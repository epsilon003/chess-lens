# ‚ôõ ChessLens ‚Äî AI Chess Analysis Web App

A full-stack chess analysis application:
- üì∑ **Image recognition**: upload a photo of any physical board ‚Üí auto-detect position
- ‚ö° **Stockfish 16 WASM**: instant in-browser engine analysis (no server round-trip)
- üíæ **Game library**: save, browse, and replay games
- üîê **Google Auth**: sign in with Google via Firebase
- üì± **Responsive**: works on phone and desktop

All free services. No paid APIs.

---

## Architecture

```
browser (React + Stockfish WASM)
    ‚Üï  REST
Express backend (Node.js)
    ‚Üï  REST
Flask vision microservice (Python + OpenCV + PyTorch)
    ‚Üï  SDK
Firebase (Auth + Firestore)
```

---

## Project Structure

```
chess-analyzer/
‚îú‚îÄ‚îÄ frontend/              # React + Vite SPA
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ components/    # Navbar, Board, AnalysisPanel, ImageUpload‚Ä¶
‚îÇ       ‚îú‚îÄ‚îÄ hooks/         # useStockfish, useAuth
‚îÇ       ‚îú‚îÄ‚îÄ pages/         # Landing, Analyze, Games, GameDetail
‚îÇ       ‚îú‚îÄ‚îÄ services/      # Firestore CRUD
‚îÇ       ‚îî‚îÄ‚îÄ workers/       # Stockfish Web Worker
‚îú‚îÄ‚îÄ backend/               # Express API (proxies to vision service)
‚îú‚îÄ‚îÄ vision-service/        # Python Flask + OpenCV + PyTorch CNN
‚îú‚îÄ‚îÄ firestore.rules        # Security rules
‚îî‚îÄ‚îÄ firebase.json          # Firebase Hosting config
```

---

## Setup Instructions

### 1 ¬∑ Firebase

1. Go to https://console.firebase.google.com
2. Create a project ‚Üí "chess-analyzer"
3. **Authentication** ‚Üí Sign-in method ‚Üí Enable **Google**
4. **Firestore Database** ‚Üí Create database ‚Üí Start in **test mode** (switch to production rules before going live)
5. **Project Settings** ‚Üí Add a Web App ‚Üí copy the `firebaseConfig` object
6. Paste it into `frontend/src/firebase.js` replacing the placeholder values
7. Deploy security rules (once Firebase CLI is installed):
   ```bash
   firebase deploy --only firestore:rules
   ```

### 2 ¬∑ Frontend

```bash
cd frontend
npm install
npm run dev          # http://localhost:5173
```

**Build for production:**
```bash
npm run build        # outputs to frontend/dist/
```

### 3 ¬∑ Backend

```bash
cd backend
cp .env.example .env      # edit VISION_SERVICE_URL if needed
npm install
npm run dev          # http://localhost:5000
```

The backend is a thin proxy ‚Äî it accepts the image upload from the browser
and forwards it to the Python vision service. It also handles CORS.

### 4 ¬∑ Vision Service

**Install Python dependencies (Python 3.10+):**
```bash
cd vision-service
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt
pip install cairosvg             # needed for synthetic dataset generation
```

**Generate a synthetic training dataset:**
```bash
python generate_dataset.py --output ./dataset --samples 300
```
This creates ~3 900 augmented piece images (300 per class √ó 13 classes).

> For a more accurate model, supplement with real photos.
> A good free dataset: search "Chess Piece Images" on Kaggle.

**Train the CNN:**
```bash
python board_recognizer.py --train --data ./dataset --epochs 30 --output model_weights.pth
```
Expected accuracy on synthetic data: ~95 %+.
On real board photos the first-time accuracy will be lower ‚Äî add real images to `./dataset` and retrain.

**Start the service:**
```bash
python app.py        # http://localhost:8000
```

---

## Running Everything Together (Development)

Open 3 terminals:

```bash
# Terminal 1 ‚Äî Vision service
cd vision-service && source venv/bin/activate && python app.py

# Terminal 2 ‚Äî Backend
cd backend && npm run dev

# Terminal 3 ‚Äî Frontend
cd frontend && npm run dev
```

Then open http://localhost:5173

---

## Deployment (Free Tier)

### Frontend ‚Üí Firebase Hosting

```bash
npm install -g firebase-tools
firebase login
firebase init hosting      # point to frontend/dist
cd frontend && npm run build
firebase deploy --only hosting
```

### Backend ‚Üí Render.com (free)

1. Push repo to GitHub
2. Create a new **Web Service** on render.com
3. Build command: `cd backend && npm install`
4. Start command: `node backend/server.js`
5. Add environment variables: `VISION_SERVICE_URL`, `ALLOWED_ORIGINS`

### Vision Service ‚Üí Render.com (free)

1. Create another **Web Service**
2. Runtime: Python 3
3. Build command: `pip install -r vision-service/requirements.txt`
4. Start command: `python vision-service/app.py`
5. Upload `model_weights.pth` as a persistent disk or re-train on deploy

Update `VISION_SERVICE_URL` in your backend env vars to the Render URL.
Update `firebase.json` rewrite to point to your deployed backend URL.

---

## Improving Recognition Accuracy

The CNN in `board_recognizer.py` uses MobileNetV3-Small.
To improve accuracy on real board photos:

1. **Collect real data** ‚Äî photograph boards from above, slice into cells, label them
2. **Use transfer learning** ‚Äî the model is initialized with ImageNet weights (`pretrained=True`)
3. **Add more augmentation** ‚Äî motion blur, perspective distortion, lighting gradients
4. **Use a larger model** ‚Äî swap MobileNetV3-Small for ResNet-34 in `build_model()`

---

## Key Tech Decisions

| Choice | Reason |
|--------|--------|
| Stockfish WASM in browser | No server cost, no latency, full depth analysis |
| Firebase Auth | Free Google OAuth without building your own auth server |
| Firestore | Free tier (50k reads/day) is plenty for student project; no SQL setup |
| MobileNetV3-Small | Fast, accurate, runs on CPU ‚Äî no GPU needed for inference |
| React + Vite | Fast dev server, great ecosystem, HMR |
| Render.com | Free hobby tier for always-on Node/Python services |

---

## Firestore Data Model

```
users/
  {uid}/
    games/
      {gameId}:
        title:     string
        notes:     string
        fen:       string        ‚Üê position FEN
        pgn:       string        ‚Üê full game PGN
        moves:     string[]      ‚Üê move history in SAN
        createdAt: Timestamp
        updatedAt: Timestamp
```

---

## License

MIT ‚Äî free for personal and academic use.
